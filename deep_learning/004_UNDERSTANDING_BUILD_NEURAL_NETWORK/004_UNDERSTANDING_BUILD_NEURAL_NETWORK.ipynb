{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132385b4-7b1a-484f-9d0c-10af5a259184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.FloatTensor(4) # 4개의 입력\n",
    "W = torch.FloatTensor(4, 3) # (4, 3) 행렬 가중치\n",
    "b = torch.FloatTensor(3) # 3개의 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d723b6a7-dbb0-4686-8ff7-eb497626b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearfunction(x, W, b):\n",
    "    y = torch.matmul(x, W) + b\n",
    "    return y\n",
    "# (1, 4) x (4, 3) = (3, )\n",
    "# (3, ) + (3, ) = (3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a7794c-8657-4eec-81a1-113346a4d7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([4, 3]) x torch.Size([4]) b torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print('W', W.shape, 'x', x.shape, 'b', b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ddbc56-a1f2-4278-b9f5-32b7c6479cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = linearfunction(x, W, b)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b25ae556-0cd6-4481-bcf8-5c669a629fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # super() 함수는 super(subclass 이름, subclass 객체).__init__()와 같이 써야 하지만\n",
    "        # 하부클래스 선언 내부에서 super()호출 시는 super().__init__()와 같이 쓰면 자동으로 두인자가 넣어져서 호출됨\n",
    "        super().__init__()\n",
    "        # __init__()에서 신경망 계층 초기화\n",
    "        self.W = torch.FloatTensor(4, 3)\n",
    "        self.b = torch.FloatTensor(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (input_dim)\n",
    "        # |y| = (input_dim) * (input_dim, output_dim) + (output_dim)\n",
    "        #     = (output_dim)\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5942bcc8-32a3-4b19-be21-251a56094ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(4)\n",
    "mylinear = NeuralNetwork()\n",
    "# forward에 넣을 인자값으로 호출하면 내부적으로 forward() 메소드를 자동 호출함(정석)\n",
    "# 내부 처리 중, forward() 전처리/후처리도 수행하므로 forward()를 직접 호출하면 전처리/후처리를 수행하지 않게 될 수 있음\n",
    "y = mylinear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe17e6f-0cc2-4c3e-9627-2555f5e112ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb70362-ca14-4002-a2ba-b61222461040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # super() 함수는 super(subclass 이름, subclass 객체).__init__()와 같이 써야 하지만\n",
    "        # 하부클래스 선언 내부에서 super()호출 시는 super().__init__()와 같이 쓰면 자동으로 두인자가 넣어져서 호출됨\n",
    "        super().__init__()\n",
    "        # __init__()에서 신경망 계층 초기화\n",
    "        self.W = torch.FloatTensor(input_dim, output_dim)\n",
    "        self.b = torch.FloatTensor(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (input_dim)\n",
    "        # |y| = (input_dim) * (input_dim, output_dim) + (output_dim)\n",
    "        #     = (output_dim)\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d977221d-26ab-4109-bf8b-93944d04d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(15)\n",
    "mylinear = NeuralNetwork(15, 5)\n",
    "y = mylinear(x)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8679a2ae-e243-4ffe-bc62-70b648fbd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # super() 함수는 super(subclass 이름, subclass 객체).__init__()와 같이 써야 하지만\n",
    "        # 하부클래스 선언 내부에서 super()호출 시는 super().__init__()와 같이 쓰면 자동으로 두인자가 넣어져서 호출됨\n",
    "        super().__init__()\n",
    "        # __init__()에서 신경망 계층 초기화\n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (input_dim)\n",
    "        # |y| = (input_dim) * (input_dim, output_dim) + (output_dim)\n",
    "        #     = (output_dim)\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81585ac9-5c87-46cb-b647-9dff685fdf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.], grad_fn=<AddBackward0>) torch.Size([5])\n",
      "Parameter containing:\n",
      "tensor([[5.0786e-35, 1.7432e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(15)\n",
    "mylinear = NeuralNetwork(15, 5)\n",
    "y = mylinear(x)\n",
    "print(y, y.shape)\n",
    "for param in mylinear.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "647e7c21-87ba-477c-8481-c20ba1cb8edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1438,  0.1331, -0.1704], grad_fn=<ViewBackward0>) torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([[-0.1671, -0.0928, -0.1145,  0.2287,  0.2371,  0.2121, -0.1970,  0.1631,\n",
      "         -0.0451,  0.0249,  0.1258,  0.1374,  0.0985, -0.1436,  0.0942],\n",
      "        [ 0.0918, -0.0025,  0.0670, -0.1604, -0.1696,  0.1433, -0.0793,  0.0577,\n",
      "         -0.2348,  0.0229, -0.1275,  0.1239, -0.0147, -0.1806, -0.0852],\n",
      "        [-0.2423,  0.1041, -0.2130, -0.0402,  0.0351, -0.0095, -0.1578, -0.1970,\n",
      "         -0.0960,  0.2460,  0.2218, -0.0343,  0.1000,  0.0886,  0.2424]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1438,  0.1331, -0.1704], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mylinear = nn.Linear(15, 3)\n",
    "y = mylinear(x)\n",
    "print(y, y.shape)\n",
    "\n",
    "for param in mylinear.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
