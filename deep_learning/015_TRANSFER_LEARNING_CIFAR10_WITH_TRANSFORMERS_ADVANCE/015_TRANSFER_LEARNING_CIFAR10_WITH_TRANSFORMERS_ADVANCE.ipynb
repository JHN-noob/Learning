{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 데이터셋\n",
        "- '비행기(airplane)', '자동차(automobile)', '새(bird)', '고양이(cat)', '사슴(deer)', '개(dog)', '개구리(frog)', '말(horse)', '배(ship)', '트럭(truck)'의 3채널(컬러), 32x32 이미지와 레이블로 구성(60,000개)\n",
        "- https:huggingface.co/datasets/cifar10"
      ],
      "metadata": {
        "id": "VBc0pAmU09xC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages\n",
        "- pip install -q 옵션 : 더 적은 출력 표시"
      ],
      "metadata": {
        "id": "jOIKkjgJ2ZCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets\n",
        "!pip install -q evaluate"
      ],
      "metadata": {
        "id": "MVXxCz_O2j64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642db3f5-b3af-4105-9175-dfca681c85e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "odt9WOJD2pfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data\n",
        "- datasets.load_dataset(데이터셋 이름, split=['train[:x]', 'test[:y]'])\n",
        "  - 전체 데이터셋 사이즈 중, train 데이터에서 x개까지, test 데이터에서 y개까지 가져온다.\n",
        "    - 해당 데아터에 train명으로 분리된 데이터셋과 test명으로 분리된 데이터셋이 이미 존재함\n",
        "  - train_test_split()을 사용하여 validation set도 구성 가능\n",
        "    - train과 test 키로 각 데이터셋이 구성됨"
      ],
      "metadata": {
        "id": "zy_VxSwM25Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_ds, test_ds = load_dataset('cifar10', split=['train[:5000]', 'test[:2000]'])\n",
        "splits = train_ds.train_test_split(test_size=0.1)\n",
        "train_ds = splits['train']\n",
        "val_ds = splits['test']\n",
        "train_ds[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195,
          "referenced_widgets": [
            "9170cf40584d4e7884314bdb03c487d5",
            "364c87f2fad847a0ad73b471e8829b9b",
            "cede3e3c953741499cd5dd9854d48072",
            "4836d8849d304aba9786a3635a2e3e69",
            "d2a2f73331e84c9c949265179645d8b3",
            "3d672955008f486a8bb0abbcd0bff534",
            "e17f98d704474658ab21a6dc8abc1bd9",
            "294f2f2445ef4595bd249a40fd9a5b46",
            "04cbb68541b74c0b98ccfeec097795f2",
            "e06156fa7d7a43938aac0889993b1500",
            "8db3d77adf364c529810b95c19fecff0",
            "2ab06c578cfe41ca873ec4283a931b12",
            "f9d2999c780f4df3bbeacaf96ed051c8",
            "ff2fddb0dfba4a2aa0d53a3cade23161",
            "05206119ac7347aba52bcf3f867b0b46",
            "b89a3291134c4765a6c5f2f606eeccd0",
            "12f65cd88e5b4ed9b38e32c31e026bae",
            "d87cb6b98912467f860ac1d54d957580",
            "eb9d0af196d0423f9bd2a55664bce57a",
            "96c9173c1e524b19bbe260281a5fcf68",
            "3ea5252889a84a4ab6ed58adfb305a2c",
            "41b96ae0dd134865b6f1b6f96a0d60db",
            "32a66177d16f4abcb88913025e4d97fd",
            "d89881c50e46440fa6325668d3daad42",
            "fe570345b5644739a181f8290d3d2615",
            "69536613945b4f32a1d7817c6d1a0f0b",
            "e236aadfda7a45f8b09bc1578229f60e",
            "a3e0bcbf194649c69e9acc2dfa5bfb58",
            "548f8c8833524683a0dafee1bef190b7",
            "cdb4d1fa17ad45d685991d076108430f",
            "bf156c65ab6c4976a10a9cf8265d24d5",
            "e2109dda9a814f0993c6980926e61909",
            "930580f919eb4cfe8d7cd86ac1ad50e4",
            "6111e841e99d433bbb29e153b80c2ae1",
            "ccc5fa489a77425fbc9d1ddc99b7f5c3",
            "2edcac70b4aa4c6bb16c78959c4aa33b",
            "cf1ee3ea09d94870a6928511b48618bb",
            "819255f744134ae1b5723cfa0b62ca4a",
            "a026270c0983498d88ebf3b433990d28",
            "c561d266a40a468d92ea1e10adb4a857",
            "ca175b09ff5042ee8f26863e38f88919",
            "1013e6885fbb4dff8c331da510d3d8d0",
            "bf719049c88e4e1dacbb20fa095c3ffa",
            "13d78bf3cdf64a82872723f1ed7af9fd",
            "64695f5226504c4e8ae0cf6eef05c2b8",
            "1d85595088154df19e20fc5fc1c3b0c3",
            "b6b79528390c4e4bb31951d0da70cb94",
            "531f2f54e78c49cf8c41d8345980a663",
            "ed318f51461947b49d3d87456e8a4cd3",
            "26de0547bf304222bb03ac2fb3e06a5c",
            "c046b82a2f83409da2115508e642c905",
            "091c330c7f8945aca0260d2347cc530e",
            "07d8cc74a08248c5854480b87577b9bd",
            "a9eaa2932daf44eb84d57e9361a290ba",
            "5a0060ebd39348c18722af9410ae2302"
          ]
        },
        "id": "Fk1SlPu35K-h",
        "outputId": "4b9da71c-bff5-463d-85a6-65a54220a4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9170cf40584d4e7884314bdb03c487d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/120M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab06c578cfe41ca873ec4283a931b12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/23.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32a66177d16f4abcb88913025e4d97fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6111e841e99d433bbb29e153b80c2ae1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64695f5226504c4e8ae0cf6eef05c2b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['img', 'label'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data\n",
        "- Vision Transformers는 동일 이미지 사이즈와 동일 채널별 Normalization 시에 성능이 좋음\n",
        "- ViTFeatureExtractor()를 통해, 해당 Pre-Trained 모델의 학습 시 적용된 config를 확인할 수 있다.\n",
        "- 채널별 픽셀값은 'pixel_values', 해당 이미지의 분류값은 'labels'에 넣어주면 해당 Pre-Trained 모델로 학습 및 예측 가능"
      ],
      "metadata": {
        "id": "T4BECl4I5ta1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "feature_extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471,
          "referenced_widgets": [
            "56b347095b4748f98c6c90812eeb3d7e",
            "60b2fba7ff984e10a3d79907bf551587",
            "e48772f314bc41aabd177980354d746b",
            "00833a4bba4e4f0bb968b879fae0137b",
            "94c1a87c0b294175b6530627276abf13",
            "c77f007a153c4d33ba37f0c50f0b5fec",
            "c53059656a4a4a2e8339094218b56fdc",
            "72fa4c1b8c274e828b092811d5f769bf",
            "153808d2d56b4509919f28d945787a0d",
            "bf6385823a5345f79c2aa5fc93b6e698",
            "f4c17da7f71e480aa544383b7a4ee7ac"
          ]
        },
        "id": "XGonQTRF6RC7",
        "outputId": "259daa79-d37f-4bf1-9a2e-9c3f811bae74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56b347095b4748f98c6c90812eeb3d7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTFeatureExtractor {\n",
              "  \"do_convert_rgb\": null,\n",
              "  \"do_normalize\": true,\n",
              "  \"do_rescale\": true,\n",
              "  \"do_resize\": true,\n",
              "  \"image_mean\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
              "  \"image_std\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"resample\": 2,\n",
              "  \"rescale_factor\": 0.00392156862745098,\n",
              "  \"size\": {\n",
              "    \"height\": 224,\n",
              "    \"width\": 224\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation\n",
        "- 적은 데이터를 증강하는 기법으로 이미지 모델에서 성능을 높이는데 기여한 기법\n",
        "- 또한 다양한 test 데이터에 대해서도 성능을 낼 수 있도록 데이터를 임의로 다양하게 변형하여 학습시키기 위해서도 많이 사용함\n",
        "- pytorch torchvision에서 제공하는 데이터셋은 데이터 변경을 용이하게 할 수 있도록 몇가지 변형을 제공함\n",
        "- 주요 함수\n",
        "  - torchvision.transforms.ToTensor() : PIL 이미지 또하는 ndarray 데이터를 텐서 형태로 변형시켜줌\n",
        "  - torchvision.transforms.Normalize(mean, std)\n",
        "    - mean, std는 각 채널별 평균과 표준편차(데이터 정규화를 위한 기법), 텐서에만 적용 가능\n",
        "    - 예: 3채널 데이터라면,\n",
        "      - 각 채널의 평균, 표준편차를 0.5로 세팅한다면\n",
        "      - transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  - torchvision.transforms.Resize(size)\n",
        "    - 이미지의 사이즈 변경\n",
        "    - 예: 이미지를 224x224로 변경하고자 한다면,\n",
        "      - transforms.Resize((224, 224))\n",
        "  - torchvision.transforms.Compose()\n",
        "    - 여러 transform을 하나로 구성하는 기능"
      ],
      "metadata": {
        "id": "osQzFXJG6hBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "transforms_for_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(tuple(feature_extractor.size.values())),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "transforms_for_val = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(tuple(feature_extractor.size.values())),\n",
        "        transforms.CenterCrop(tuple(feature_extractor.size.values())),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "def train_transforms(imagedata):\n",
        "  imagedata['pixel_values'] = [transforms_for_train(image.convert(\"RGB\")) for image in imagedata['img']]\n",
        "  return imagedata\n",
        "\n",
        "def test_transforms(imagedata):\n",
        "  imagedata['pixel_values'] = [transforms_for_val(image.convert(\"RGB\")) for image in imagedata['img']]\n",
        "  return imagedata\n",
        "\n",
        "# Set the transforms\n",
        "train_ds.set_transform(train_transforms)\n",
        "val_ds.set_transform(test_transforms)\n",
        "test_ds.set_transform(test_transforms)\n",
        "\n",
        "print(train_ds[0].keys())\n",
        "print(type(train_ds[0]['img']))\n",
        "print(type(train_ds[0]['label']), train_ds[0]['label'])\n",
        "print(type(train_ds[0]['pixel_values']), train_ds[0]['pixel_values'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc1RK--UDLnl",
        "outputId": "079641f1-9a5a-4db8-b7fd-d809261cc915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['img', 'label', 'pixel_values'])\n",
            "<class 'PIL.PngImagePlugin.PngImageFile'>\n",
            "<class 'int'> 1\n",
            "<class 'torch.Tensor'> torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer 활용을 위해 필요한 data_collator 함수\n",
        "- 인덱스 번호 기반 데이터셋(map-style dataset)을 기반으로 mini_batch 구성 시 샘플을 리스트로 합쳐주는 기능을 구현해야한다."
      ],
      "metadata": {
        "id": "3tC622sEFXfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "def collate_fn(imagedata):\n",
        "  pixel_values = torch.stack([example[\"pixel_values\"] for example in imagedata])\n",
        "  # \"pixel_values\" 텐서들만 꺼내서 스택으로 쌓음\n",
        "  labels = torch.tensor([example[\"label\"] for example in imagedata])\n",
        "  # label 값들을 꺼내서 텐서로 만듦\n",
        "  return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# DataLoader 사용 시에는 다음과 같이 사용할 수 있다.\n",
        "# train_dataloader = DataLoader(train_ds, collate_fn=collate_fn, batch_size=16)"
      ],
      "metadata": {
        "id": "jm1T8onQRlGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "wSDHLFbNTOFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {id: label for id, label in enumerate(train_ds.features['label'].names)}\n",
        "label2id = {label: id for id, label in id2label.items()}\n",
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXBWUJjhTgnM",
        "outputId": "c5387590-9fa9-4ba5-bc80-799f5d76ed2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'airplane',\n",
              " 1: 'automobile',\n",
              " 2: 'bird',\n",
              " 3: 'cat',\n",
              " 4: 'deer',\n",
              " 5: 'dog',\n",
              " 6: 'frog',\n",
              " 7: 'horse',\n",
              " 8: 'ship',\n",
              " 9: 'truck'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgUBnSJ8Tzp3",
        "outputId": "f68f0773-8a41-40cc-f9f3-de28680b22a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'airplane': 0,\n",
              " 'automobile': 1,\n",
              " 'bird': 2,\n",
              " 'cat': 3,\n",
              " 'deer': 4,\n",
              " 'dog': 5,\n",
              " 'frog': 6,\n",
              " 'horse': 7,\n",
              " 'ship': 8,\n",
              " 'truck': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k',\n",
        "                                                  num_labels = 10,\n",
        "                                                  id2label = id2label,\n",
        "                                                  label2id = label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "599ffcd13e95465887563597671293ac",
            "91e1628d361340f78559ff1affbf8f4c",
            "82ea39e2c8a64d5ea76abf99783990e2",
            "cd8fe6c54918419e85758ecef2d49e32",
            "909674e415b9499baecef05a826a3f7a",
            "69106925765c466784eba0317c8d0163",
            "1123ebb747264b4b90fae41af20cb97b",
            "e672796433cd4f06a60aae336a237dd9",
            "c19f724c5bef483e8ae4a2b81e71c887",
            "c8525f0bc196474980c5ba9329f3e07b",
            "269f1efa59054c4785d858d8eabd38be",
            "b443387576a24757b73e22dd16c4da1c",
            "fb76e0336ff7417faa4bfbe566f33c30",
            "b93817ef400746b9a467d0fa7a5dd770",
            "2896f5aedf5f49f0aba065488f515070",
            "369e91744a9948fd976a8666601cf00d",
            "76412ac62bbb4ef29a8c0bd79d559080",
            "c255c792783d4f64b76d1d341ce17c9a",
            "97d6d81c8b40424e8e131a8f83f027f4",
            "29e4bf3b630244bc902aa551ec380be8",
            "975b4ea46eed497f844b0e4166720a3a",
            "e8c417fd739244c1b881e18b753d65e8"
          ]
        },
        "id": "HDRAnesYUADz",
        "outputId": "8af7bd98-1eeb-4441-f8d6-52ba976dea02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "599ffcd13e95465887563597671293ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b443387576a24757b73e22dd16c4da1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyIaSaOcUmFJ",
        "outputId": "1516e9b8-1c31-4fc7-9623-b1ab70765a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTConfig {\n",
              "  \"architectures\": [\n",
              "    \"ViTModel\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.0,\n",
              "  \"dtype\": \"float32\",\n",
              "  \"encoder_stride\": 16,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.0,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"airplane\",\n",
              "    \"1\": \"automobile\",\n",
              "    \"2\": \"bird\",\n",
              "    \"3\": \"cat\",\n",
              "    \"4\": \"deer\",\n",
              "    \"5\": \"dog\",\n",
              "    \"6\": \"frog\",\n",
              "    \"7\": \"horse\",\n",
              "    \"8\": \"ship\",\n",
              "    \"9\": \"truck\"\n",
              "  },\n",
              "  \"image_size\": 224,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"airplane\": 0,\n",
              "    \"automobile\": 1,\n",
              "    \"bird\": 2,\n",
              "    \"cat\": 3,\n",
              "    \"deer\": 4,\n",
              "    \"dog\": 5,\n",
              "    \"frog\": 6,\n",
              "    \"horse\": 7,\n",
              "    \"ship\": 8,\n",
              "    \"truck\": 9\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"model_type\": \"vit\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_channels\": 3,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"patch_size\": 16,\n",
              "  \"pooler_act\": \"tanh\",\n",
              "  \"pooler_output_size\": 768,\n",
              "  \"qkv_bias\": true,\n",
              "  \"transformers_version\": \"4.56.2\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer 실행을 위해 필요한 아규먼트 설정"
      ],
      "metadata": {
        "id": "_O57OGSeU4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir = \"test-cifar-10\", # 모델 예측과 체크포인트가 저장되는 폴더명\n",
        "    save_strategy = \"epoch\", # epoch마다 모델 학습 전략\n",
        "    eval_strategy = \"epoch\", # evaluation 시, epoch마다 모델 학습 전략\n",
        "    learning_rate = 2e-5, # 0.00002\n",
        "    per_device_train_batch_size = 16, # CPU/GPU 당 mini-batch 사이즈\n",
        "    per_device_eval_batch_size = 16, # evaluation 시, CPU/GPU 당 mini-batch 사이즈\n",
        "    num_train_epochs = 10, # 총 학습 에포크\n",
        "    weight_decay = 0.01, # optimizer에 들어갈 weight decay\n",
        "    load_best_model_at_end = True, # 학습 종료시 자동으로 베스트 모델을 로드한다.\n",
        "    metric_for_best_model = \"accuracy\", # 베스트 모델 측정을 위한 메트릭(정확도)\n",
        "    logging_dir = \"logs\", # Tensorboard를 위한 logs를 저장할 폴더명\n",
        "    report_to = \"none\", # wandb 자동 로깅 비활성화\n",
        "    remove_unused_columns = False, # 자동으로 모델에서 쓰지않는 컬럼 삭제 여부\n",
        "    optim = \"adamw_torch\", # pytorch에서 제공하는 AdamW optimizer 사용\n",
        "    lr_scheduler_type = \"constant\", # learning rate scheduler, 고정시 학습률 고정(default: linear)\n",
        "    save_total_limit = 10 # 저장할 checkpoints 최대 갯수(저장용량 초과 에러 방지)\n",
        ")"
      ],
      "metadata": {
        "id": "7M-tjdfxU_Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric 설정"
      ],
      "metadata": {
        "id": "omwX8T6vVP4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  # 예측(검증)값과 실제값을 가져온다.\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  # 예측값 중 가장 높은 값의 인덱스 번호를 저장\n",
        "  return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "nTr2Xqq8ZBJt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b7b2c7587a514cdaa3fa61774e83e5e0",
            "89d0ff1710b94244a4799aa2de8cd888",
            "35bb9305adf645e28c91c8154cd2603e",
            "4ee821cddeaf48feac0e70f1f0ad44e0",
            "24ea2fe369de499c856f59688f26a95a",
            "bbb3fa11a47e41069dfb8fce027993d4",
            "dfe19a35b2554aa69ce02a739d6b6aef",
            "48fa846e351e45f5989ebf76b68188ad",
            "a73052a374c342639a269d184c50b349",
            "c58fb13f6f9842f5aad5db5df69fa40c",
            "a2915110477e47b38d888377bf0669f6"
          ]
        },
        "outputId": "70bca844-7fe5-49db-aa3a-240c6cc6cac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7b2c7587a514cdaa3fa61774e83e5e0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer 정의 및 실행"
      ],
      "metadata": {
        "id": "CeJYk0-baBi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = args,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset = val_ds,\n",
        "    data_collator = collate_fn,\n",
        "    compute_metrics = compute_metrics,\n",
        "    tokenizer = feature_extractor\n",
        ")"
      ],
      "metadata": {
        "id": "rF2gP_bcbgOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "ar0lnYY5b2Dw",
        "outputId": "e96a3dd5-08ed-4e23-80df-ae4619874043"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1275' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1275/2820 13:04 < 15:51, 1.62 it/s, Epoch 4.52/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.660980</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.958200</td>\n",
              "      <td>0.289969</td>\n",
              "      <td>0.966000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.958200</td>\n",
              "      <td>0.203597</td>\n",
              "      <td>0.956000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>0.170226</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2820' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2820/2820 28:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.660980</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.958200</td>\n",
              "      <td>0.289969</td>\n",
              "      <td>0.966000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.958200</td>\n",
              "      <td>0.203597</td>\n",
              "      <td>0.956000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>0.170226</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>0.167841</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.051400</td>\n",
              "      <td>0.168710</td>\n",
              "      <td>0.962000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.051400</td>\n",
              "      <td>0.156244</td>\n",
              "      <td>0.966000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.029400</td>\n",
              "      <td>0.162407</td>\n",
              "      <td>0.962000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.164899</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.166887</td>\n",
              "      <td>0.962000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2820, training_loss=0.21528698053765805, metrics={'train_runtime': 1734.2926, 'train_samples_per_second': 25.947, 'train_steps_per_second': 1.626, 'total_flos': 3.48738956568576e+18, 'train_loss': 0.21528698053765805, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "-TmPvK-9wQxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = trainer.predict(test_ds)"
      ],
      "metadata": {
        "id": "uhnTStu7pBY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a6bb120c-9d8f-4556-bfa7-f3e39fdd0ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.metrics)"
      ],
      "metadata": {
        "id": "4fMuoTwPpExe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97efcb5d-fe90-41fa-d789-8d6c4dc4fb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'test_loss': 0.28015777468681335, 'test_accuracy': 0.971, 'test_runtime': 26.4441, 'test_samples_per_second': 75.631, 'test_steps_per_second': 4.727}\n"
          ]
        }
      ]
    }
  ]
}